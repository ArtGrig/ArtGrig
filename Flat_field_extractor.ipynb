{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flat-field_extractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1geDLVNOoBIRcv-5zP5585i1TuCI5P1Xu",
      "authorship_tag": "ABX9TyPzmp6+36rtiyj3b9kJj3al",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtGrig/ArtGrig/blob/main/Flat_field_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Библиотеки"
      ],
      "metadata": {
        "id": "zq6sG268321T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "pPJwcEBy3sHl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "import os\n",
        "from keras import backend as K\n",
        "from keras.models import Model, Input\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "H5rvgAEC4fnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подключение к Google Drive"
      ],
      "metadata": {
        "id": "JIIfde-Y8hSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/Data/'"
      ],
      "metadata": {
        "id": "pghGQj1o4bxq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание датасета"
      ],
      "metadata": {
        "id": "TXoCaXWk86Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataUpload(file_name, IMG_WIGHT, IMG_HEIGHT, IMG_CHANNELS):\n",
        "  \"\"\"\n",
        "  Input: полный путь к файлу с изображениями в формате hdf5, ширину, высоту, кол-во каналов\n",
        "  Do: загружает изображения и сохраняет их numpy массиве \n",
        "  Output: датасет вида (кол-во изображений, ширина, высота, кол-во каналов)\n",
        "  \"\"\"\n",
        "  res = []\n",
        "\n",
        "  with h5py.File(file_name, 'r') as f: \n",
        "    def print_attrs(name):\n",
        "      t = name.split('/')\n",
        "      temp = ''\n",
        "      for i in range(len(t)-1):\n",
        "        temp += t[i]\n",
        "        if not (temp in res):\n",
        "          res.append(temp)\n",
        "\n",
        "    f.visit(print_attrs)\n",
        "\n",
        "  if res:\n",
        "      path = input(f\"Ввберите какие файлы загрузить: {res}\\n\")\n",
        "      with h5py.File(file_name, 'r') as f: \n",
        "        KeysList = list(f[path].keys())\n",
        "        output = np.zeros((len(KeysList), IMG_HEIGHT, IMG_WIGHT, IMG_CHANNELS), dtype=np.float32)\n",
        "\n",
        "        for i in range(len(KeysList)):\n",
        "          data = np.array(f[f'{path}/{KeysList[i]}'])\n",
        "          output[i] = np.reshape(data, (IMG_WIGHT,IMG_HEIGHT,IMG_CHANNELS))\n",
        "\n",
        "  else:\n",
        "      with h5py.File(file_name, 'r') as f: \n",
        "        KeysList = list(f.keys())\n",
        "        output = np.zeros((len(KeysList), IMG_HEIGHT, IMG_WIGHT, IMG_CHANNELS), dtype=np.float32)\n",
        "\n",
        "        for i in range(len(KeysList)):\n",
        "          data = np.array(f[f'{KeysList[i]}'])\n",
        "          output[i] = np.reshape(data, (IMG_WIGHT,IMG_HEIGHT,IMG_CHANNELS))\n",
        "\n",
        "  return(output)"
      ],
      "metadata": {
        "id": "jl5UQu1L6TFn"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Отрисовка даных"
      ],
      "metadata": {
        "id": "mM2lyUa7TCpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotExamples(dset, n_samp=3):\n",
        "  \"\"\"\n",
        "  Input: numpy массив с изображениями вида (кол-во изображений, ширина, высота, кол-во каналов), кол-во изображений для отрисовки\n",
        "  Do: в случайном порядке выбирает изображения из датасета и отрисовывает их\n",
        "  Output: ничего\n",
        "  \"\"\"\n",
        "  examples = np.random.randint(len(X_train[0]), size=n_samp)\n",
        "\n",
        "  plt.figure(figsize=(20, 20), dpi=80)\n",
        "\n",
        "  for i, n in enumerate(examples):\n",
        "    plt.subplot(2, n_samp, n_samp+1+i)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(dset[n, :, :, 0])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "jY69ig8vHBQX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Стандартизация данных"
      ],
      "metadata": {
        "id": "ZuY7fMBEUBNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standart(dset, dataMean=None, dataStd=None):\n",
        "  \"\"\"\n",
        "  Input: numpy массив с изображениями вида (кол-во изображений, ширина, высота, кол-во каналов), \n",
        "  среднее значение пикселей и стандартное отклонение, если необходимо стандартизировать по уже имеющимся данным\n",
        "  Do: при необходимости расчитывает среднее значение пикселей и стандартное отклонение,\n",
        "  вычитает попиксельно среднее значение и делит на стандартное отклонение,\n",
        "  печатает среднее значение пикселей и стандартное отклонение после стандартизации\n",
        "  Output: numpy массив с изображениями вида (кол-во изображений, ширина, высота, кол-во каналов), \n",
        "  среднее значение пикселей и стандартное отклонение\n",
        "  \"\"\"\n",
        "  if not (dataMean) or not (dataStd):\n",
        "    dataMean = dset.mean()\n",
        "    dataStd = np.std(dset)\n",
        "\n",
        "  dset = (dset - dataMean)/dataStd\n",
        "\n",
        "  print('Mean: ', dset.mean(), 'Std: ', np.std(dset))\n",
        "\n",
        "  return dset, dataMean, dataStd"
      ],
      "metadata": {
        "id": "jhpFGTv-VeGx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель"
      ],
      "metadata": {
        "id": "GgxBVnKZs7hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дискриминатор"
      ],
      "metadata": {
        "id": "oZ-OCCMUtF7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(image_shape):\n",
        "  \"\"\"\n",
        "  Создает модель дискриминатора\n",
        "  \"\"\"\n",
        "\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "\n",
        "  in_src_image = Input(shape=image_shape) # Изображение, которое хотим преобразовать\n",
        "  in_target_image = Input(shape=image_shape) # Изображение, которое хотим получить\n",
        "\n",
        "  merged = Concatenate()([in_src_image, in_target_image])\n",
        "\n",
        "  d = Conv2D(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init,)(merged)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init,)(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init,)(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init,)(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init,)(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d = Conv2D(1, (4, 4), padding='same', kernel_initializer=init)(d)\n",
        "  patch_out = Activation('sigmoid')(d)\n",
        "\n",
        "  model = Model([in_src_image, in_target_image], patch_out)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, loss_weights=[0.5])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "7SK5YjFJtjJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генератор"
      ],
      "metadata": {
        "id": "y-upd4ubu3NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "  \"\"\"\n",
        "  Блок энкодера в генераторе\n",
        "  \"\"\"\n",
        "\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "\n",
        "  g = Conv2D(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\n",
        "  if batchnorm:\n",
        "    g = BatchNormalization()(g, training=True)\n",
        "\n",
        "  g = LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "  return g"
      ],
      "metadata": {
        "id": "peRfmJ5BvEqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "  \"\"\"\n",
        "  Блок декодера в генераторе\n",
        "  \"\"\"\n",
        "  init = RandomNormal(stddev=0.2)\n",
        "\n",
        "  g = Conv2DTranspose(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
        "  g = BatchNormalization()(g, training=True)\n",
        "\n",
        "  if dropout:\n",
        "    g = Dropout(0.3)(g, training=True)\n",
        "\n",
        "  g = Concatenate()([g, skip_in])\n",
        "\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  return g"
      ],
      "metadata": {
        "id": "SSQPOy2SvHTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(image_shape=(256, 256, 3)):\n",
        "  \"\"\"\n",
        "  Создает модель из блоков, определенных выше\n",
        "  \"\"\"\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  e1 = encoder_block(in_image, 64, batchnorm=False)\n",
        "  e2 = encoder_block(e1, 128)\n",
        "  e3 = encoder_block(e2, 256)\n",
        "  e4 = encoder_block(e3, 512)\n",
        "  e5 = encoder_block(e4, 512)\n",
        "  e6 = encoder_block(e5, 512)\n",
        "  e7 = encoder_block(e6, 512)\n",
        "\n",
        "  b = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(e7)\n",
        "  b = Activation('relu')(b)\n",
        "\n",
        "  d1 = decoder_block(b, e7, 512)\n",
        "  d2 = decoder_block(d1, e6, 512)\n",
        "  d3 = decoder_block(d2, e5, 512)\n",
        "  d4 = decoder_block(d3, e4, 512, dropout=False)\n",
        "  d5 = decoder_block(d4, e3, 256, dropout=False)\n",
        "  d6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "  d7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "\n",
        "  g = Conv2DTranspose(image_shape[2], (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d7)\n",
        "  # out_image = Activation('sigmoid')(g)\n",
        "  # out_image = Activation('tanh')(g)\n",
        "  # out_image = LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "  model = Model(in_image, g)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "eBxEtVdqu_fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN"
      ],
      "metadata": {
        "id": "fKfwABEcwKfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gan(g_model, d_model, image_shape):\n",
        "  \"\"\"\n",
        "  Создает GAN модель из дискриминатора и генератора \n",
        "  \"\"\"\n",
        "  for layer in d_model.layers:\n",
        "    if not isinstance(layer, BatchNormalization):\n",
        "      layer.trainable = False\n",
        "\n",
        "  in_src = Input(shape=image_shape)\n",
        "  gen_out = g_model(in_src)\n",
        "  dis_out = d_model([in_src, gen_out])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "  model = Model(in_src, [dis_out, gen_out])\n",
        "  model.compile(loss=['binary_crossentropy','mae'], optimizer=optimizer, loss_weights=[1, 5000])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "J5t2Qyi2wPYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции для обучения"
      ],
      "metadata": {
        "id": "kHkFO7JXwlsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация образцов для обучения"
      ],
      "metadata": {
        "id": "35C73i0OyWlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples(TrainA, TrainB, n_samples, patch_shape):\n",
        "  \"\"\"\n",
        "  Берет случайные пары элементов из датасетов обучения и помечает их единицами\n",
        "  \"\"\"\n",
        "  n = np.random.randint(0, TrainA.shape[0], n_samples)\n",
        "  x1, x2 = TrainA[n], TrainB[n]\n",
        "  y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
        "  return [x1, x2], y"
      ],
      "metadata": {
        "id": "JPRsTLi0yag0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "  \"\"\"\n",
        "  Создает при помощи генератора образцы и помечает их нулями\n",
        "  \"\"\"\n",
        "  x = g_model.predict(samples)\n",
        "  y = np.zeros((len(x), patch_shape, patch_shape, 1))\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "VRcMZBmYycYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функция обучения"
      ],
      "metadata": {
        "id": "i263UNoTx0hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(d_model, g_model, gan_model, trainA, trainB, n_epochs=100, n_batch=1):\n",
        "\tn_patch = d_model.output_shape[1]\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\td_loss_hist = []\n",
        "\tg_loss_hist = []\n",
        "\t# val_loss_hist = []\n",
        "\n",
        "\tfor i in range(n_steps):\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(trainA, trainB, n_batch, n_patch)\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\td_loss_hist.append((d_loss2+d_loss2)/2)\n",
        "\t\tg_loss_hist.append(g_loss)\n",
        "\t\tprint('>%d/%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, n_steps, d_loss1, d_loss2, g_loss))\n",
        "\t\n",
        "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, trainA, trainB)\n",
        "\t \n",
        "\treturn d_loss_hist, g_loss_hist"
      ],
      "metadata": {
        "id": "qORvc-lGx4a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Итоги обучения и сохранение модели"
      ],
      "metadata": {
        "id": "x-N2DXq7xsOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_performance(step, g_model, TrainA, TrainB, n_samples=3):\n",
        "\t[X_realA, X_realB], _ = generate_real_samples(TrainA, TrainB, n_samples, 1)\n",
        "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        " \n",
        "\tprint('>Generator PSNR: ', PSNR(X_fakeB, X_realA))\n",
        "\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_realA[i, :, :, 0])\n",
        "\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_fakeB[i, :, :, 0])\n",
        "\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_realB[i, :, :, 0])\n",
        "\n",
        "\tfilename1 = 'plot_%06d.png' % (step+1)\n",
        "\tplt.savefig(filename1)\n",
        "\tplt.close()\n",
        "\n",
        "\tfilename2 = 'model_%06d.h5' % (step+1) # Сохранение модели генератора\n",
        "\toptimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\tg_model.compile(loss=['binary_crossentropy', 'mae'], optimizer=optimizer, loss_weights=[1, 5000])\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "metadata": {
        "id": "XUDaTlMkxrtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение GAN"
      ],
      "metadata": {
        "id": "r3nFk8sVyEeY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYZh3JaXzWum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}